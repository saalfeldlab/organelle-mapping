{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import zarr\n",
    "import fibsem_tools as fst\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../all_data.yaml\") as f:\n",
    "    datas = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jrc_cos7-1a\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(385, 400, 400)\n",
      "(299, 400, 400)\n",
      "(400, 400, 400)\n",
      "(1796, 1500, 2400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(450, 600, 1100)\n",
      "(400, 400, 400)\n",
      "jrc_cos7-1b\n",
      "(400, 400, 400)\n",
      "(279, 900, 1600)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(285, 400, 400)\n",
      "(243, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_ctl-id8-1\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_fly-mb-1a\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_fly-vnc-1\n",
      "(600, 600, 600)\n",
      "(500, 500, 500)\n",
      "(400, 600, 600)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 600, 600)\n",
      "jrc_hela-2\n",
      "(200, 1000, 1000)\n",
      "(500, 800, 800)\n",
      "(476, 600, 600)\n",
      "(500, 500, 500)\n",
      "(160, 600, 600)\n",
      "(200, 400, 400)\n",
      "(106, 200, 200)\n",
      "(220, 320, 320)\n",
      "(130, 300, 300)\n",
      "(128, 300, 300)\n",
      "(400, 400, 400)\n",
      "(220, 400, 400)\n",
      "(110, 300, 300)\n",
      "(500, 500, 500)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(500, 1000, 1000)\n",
      "(800, 800, 800)\n",
      "jrc_hela-3\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(512, 512, 512)\n",
      "(512, 512, 512)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(980, 440, 620)\n",
      "(400, 400, 400)\n",
      "(600, 600, 600)\n",
      "(1000, 500, 1000)\n",
      "(400, 400, 400)\n",
      "jrc_jurkat-1\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(512, 512, 512)\n",
      "(512, 512, 512)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(1000, 500, 1000)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_macrophage-2\n",
      "(300, 300, 300)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(512, 512, 512)\n",
      "(512, 512, 512)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(1002, 500, 1004)\n",
      "jrc_mus-heart-1\n",
      "(400, 400, 400)\n",
      "(400, 400, 390)\n",
      "jrc_mus-kidney\n",
      "(300, 300, 300)\n",
      "(200, 200, 200)\n",
      "(300, 300, 300)\n",
      "(200, 200, 180)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(600, 600, 600)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(500, 500, 500)\n",
      "(400, 300, 300)\n",
      "(300, 300, 300)\n",
      "(600, 1000, 1400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_mus-kidney-3\n",
      "(300, 200, 200)\n",
      "jrc_mus-kidney-glomerulus-2\n",
      "(584, 550, 550)\n",
      "jrc_mus-liver\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(100, 400, 400)\n",
      "(200, 200, 200)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(360, 750, 750)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(400, 124, 400)\n",
      "(500, 500, 400)\n",
      "(800, 300, 600)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(400, 124, 400)\n",
      "(500, 500, 400)\n",
      "jrc_mus-liver-3\n",
      "(300, 300, 300)\n",
      "jrc_mus-liver-zon-1\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(500, 1000, 3000)\n",
      "(1000, 1000, 1000)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(500, 500, 500)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(500, 500, 500)\n",
      "(500, 1000, 1000)\n",
      "(1000, 1000, 2000)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(400, 400, 600)\n",
      "(400, 400, 600)\n",
      "(1000, 1000, 1000)\n",
      "(600, 400, 600)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "jrc_mus-liver-zon-2\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(600, 400, 600)\n",
      "(600, 400, 600)\n",
      "(200, 200, 200)\n",
      "(200, 200, 200)\n",
      "(1500, 1500, 1500)\n",
      "(1500, 1500, 1500)\n",
      "(600, 400, 600)\n",
      "(600, 400, 600)\n",
      "(1000, 1000, 1000)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(200, 200, 200)\n",
      "(400, 400, 400)\n",
      "jrc_mus-nacc-1\n",
      "(600, 600, 600)\n",
      "jrc_sum159-1\n",
      "(170, 400, 400)\n",
      "(200, 340, 340)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_sum159-4\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(800, 800, 800)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_ut21-1413-003\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "(400, 400, 400)\n",
      "jrc_zf-cardiac-1\n",
      "(500, 500, 500)\n",
      "(500, 500, 500)\n",
      "(500, 200, 200)\n",
      "(500, 200, 200)\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset_info in datas[\"datasets\"].items():\n",
    "    print(dataset_name)\n",
    "    if not os.path.exists(dataset_info[\"em\"][\"data\"]):\n",
    "        raise FileNotFoundError(f\"Data file {dataset_info['data']} not found\")\n",
    "    if not os.path.exists(dataset_info[\"labels\"][\"data\"]):\n",
    "        raise FileNotFoundError(f\"Labels file {dataset_info['labels']} not found\")\n",
    "    em_data = zarr.open(dataset_info[\"em\"][\"data\"], \"r\")\n",
    "    try:\n",
    "        em_data[dataset_info[\"em\"][\"group\"]]\n",
    "    except KeyError:\n",
    "        print(f\"Key '{dataset_info['em']['group']}' not found in {em_data.path}\")\n",
    "        print(f\"Available keys: {list(em_data.keys())}\")\n",
    "        raise\n",
    "    labels_data = zarr.open(dataset_info[\"labels\"][\"data\"], \"r\")\n",
    "    try:\n",
    "        crop_group = labels_data[dataset_info[\"labels\"][\"group\"]]\n",
    "        for crop in dataset_info[\"labels\"][\"crops\"]:\n",
    "            ll = crop_group[crop].attrs[\"cellmap\"][\"annotation\"][\"class_names\"][0]\n",
    "            print(crop_group[crop][ll][\"s0\"].shape)\n",
    "    except KeyError:\n",
    "        print(f\"Key '{dataset_info['labels']['group']}' not found in {labels_data.path}\")\n",
    "        print(f\"Available keys: {list(labels_data.keys())}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, crops in datas.items():\n",
    "    print(key, \"-\", os.path.exists(f\"/nrs/cellmap/data/{key}\"), \"-\", os.path.exists(f\"/nrs/cellmap/data/{key}/staging/groundtruth.zarr\"))\n",
    "    classes = set()\n",
    "    for crop in crops:\n",
    "        if not os.path.exists(f\"/nrs/cellmap/data/{key}/staging/groundtruth.zarr/{crop}\"):\n",
    "            print(crop)\n",
    "        else:\n",
    "            crop_zarr = zarr.open(f\"/nrs/cellmap/data/{key}/staging/groundtruth.zarr/{crop}\", \"r\")\n",
    "            classes = classes.union(set(crop_zarr.attrs[\"cellmap\"][\"annotation\"][\"class_names\"]))\n",
    "    print(classes)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data.yaml\") as f:\n",
    "    datas = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_gt_path = \"/nrs/saalfeld/heinrichl/data/cellmap_labels/fly_organelles/\"\n",
    "root_data_path = \"/nrs/cellmap/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ds_info in datas.items():\n",
    "    print(key, \"-\", os.path.exists(f\"{root_gt_path}{key}\"), \"-\", os.path.exists(f\"{root_gt_path}{key}/groundtruth.zarr\"), \"-\", os.path.exists(f\"{ds_info['raw']}/s0\"))\n",
    "    for crop in ds_info[\"crops\"]:\n",
    "        if not os.path.exists(f\"{root_gt_path}{key}/groundtruth.zarr/{crop}\"):\n",
    "            print(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_offset(data, crop, orig_offset, new_offset):\n",
    "    diff_offset = np.array(orig_offset) - np.array(new_offset)\n",
    "    crop_root = fst.access(f\"{root_gt_path}{data}/groundtruth.zarr/{crop}\", mode=\"r+\")\n",
    "    for lbl in list(crop_root.keys()):\n",
    "        crop_label_root = crop_root[lbl]\n",
    "        ms_attrs = crop_label_root.attrs[\"multiscales\"]\n",
    "        for ds in range(len(ms_attrs[0][\"datasets\"])):\n",
    "            for k in range(len(ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"])):\n",
    "                if ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"][k][\"type\"] == \"translation\":\n",
    "                    transl = ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"][k][\"translation\"] \n",
    "                    ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"][k][\"translation\"] = list(np.array(transl) - diff_offset)\n",
    "        crop_label_root.attrs[\"multiscales\"] = ms_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fix_scale(data, crop):\n",
    "#     crop_root = fst.access(f\"{root_gt_path}{data}/groundtruth.zarr/{crop}\", mode=\"r+\")\n",
    "#     for lbl in list(crop_root.keys()):\n",
    "#         crop_label_root = crop_root[lbl]\n",
    "#         ms_attrs = crop_label_rrot.attrs[\"multiscales\"]\n",
    "#         for ds in range(len(ms_attrs[0][\"datasets\"])):\n",
    "#             for k in range(len(ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"])):\n",
    "#                 if ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"][k][\"type\"] == \"scale\":\n",
    "#                     scale = ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"][k][\"scale\"]\n",
    "#                     scale = [scale[1],]*3\n",
    "#                     print(scale)\n",
    "#                     #ms_attrs[0][\"datasets\"][ds][\"coordinateTransformations\"][k][\"scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for crop in datas[\"culture/jrc_ctl-id8-1\"][\"crops\"]:\n",
    "#     fix_scale(\"cutlure/jrc_ctl-id8-1\", crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ds_info in datas.items():\n",
    "    print(key)\n",
    "    root_raw = fst.read(ds_info[\"raw\"])\n",
    "    try:\n",
    "        datasets = root_raw.attrs[\"multiscales\"][0][\"datasets\"]\n",
    "    except KeyError as e:\n",
    "        print(\"Different metadata format?\")\n",
    "        continue\n",
    "    for ds in datasets:\n",
    "        if ds[\"path\"] == \"s0\":\n",
    "            raw_res = ds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    raw_res_arr = np.array(raw_res)\n",
    "    for crop in ds_info[\"crops\"]:\n",
    "        crop_root = fst.read(f\"{root_gt_path}{key}/groundtruth.zarr/{crop}\")\n",
    "        lbl = list(crop_root.keys())[0]\n",
    "        crop_datasets = crop_root[lbl].attrs[\"multiscales\"][0][\"datasets\"]\n",
    "        for cds in crop_datasets:\n",
    "            if cds[\"path\"] == \"s0\":\n",
    "                crop_res = cds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "                crop_off = cds[\"coordinateTransformations\"][1][\"translation\"]\n",
    "                crop_off_arr = np.array(crop_off)\n",
    "                crop_res_arr = np.array(crop_res)\n",
    "                corner_off_arr = (crop_off_arr + raw_res_arr/2. - crop_res_arr/2.)\n",
    "                print(\"########################\")\n",
    "                if np.all(corner_off_arr % raw_res_arr == 0) and np.all(corner_off_arr % crop_res_arr == 0):\n",
    "                    print(crop, \"GOOD\", raw_res, crop_res, crop_off)\n",
    "                else:\n",
    "                    print(crop, \"BAD\")\n",
    "                    print(\"RAW -\", raw_res, \"; CROP -\", crop_res, \"@\", crop_off,\"->\", corner_off_arr)\n",
    "                    if np.all(crop_res < raw_res):\n",
    "                        crop_off_arr_suggested = crop_off_arr - crop_res_arr/2.\n",
    "                        corner_off_arr_suggested = (crop_off_arr_suggested + raw_res_arr/2. - crop_res_arr/2.)\n",
    "                        if np.all(corner_off_arr_suggested % raw_res_arr == 0) and np.all(corner_off_arr_suggested % crop_res_arr == 0):\n",
    "                            print(\"SUGGESTED WORKS:\", \"suggested offset:\", list(crop_off_arr_suggested))\n",
    "                            fix_offset(key, crop, crop_off, list(crop_off_arr_suggested))\n",
    "                        else:\n",
    "                            print(\"SUGGESTED STILL BAD\")\n",
    "                    else:\n",
    "                        crop_off_arr_suggested = crop_off_arr + crop_res_arr/2. - raw_res_arr/2.\n",
    "                        corner_off_arr_suggested = (crop_off_arr_suggested + raw_res_arr/2. - crop_res_arr/2.)\n",
    "                        if np.all(corner_off_arr_suggested % raw_res_arr == 0) and np.all(corner_off_arr_suggested % crop_res_arr == 0):\n",
    "                            print(\"SUGGESTED WORKS:\", \"suggested offset:\", list(crop_off_arr_suggested))\n",
    "                            fix_offset(key, crop, crop_off, list(crop_off_arr_suggested))\n",
    "                        else:\n",
    "                            print(\"SUGGESTED STILL BAD\")\n",
    "                        #print(\"IS DIVISIBLE: \", np.all(crop_off_arr%crop_res_arr == 0))\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ds_info in datas.items():\n",
    "    print(key)\n",
    "    root_raw = fst.read(ds_info[\"raw\"])\n",
    "    try:\n",
    "        datasets = root_raw.attrs[\"multiscales\"][0][\"datasets\"]\n",
    "    except KeyError as e:\n",
    "        print(\"Different metadata format?\")\n",
    "        continue\n",
    "    for ds in datasets:\n",
    "        if ds[\"path\"] == \"s0\":\n",
    "            raw_res = ds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    raw_res_arr = np.array(raw_res)\n",
    "        \n",
    "    for crop in ds_info[\"crops\"]:\n",
    "        crop_root = fst.read(f\"{root_gt_path}{key}/groundtruth.zarr/{crop}\")\n",
    "        lbl = list(crop_root.keys())[0]\n",
    "        crop_datasets = crop_root[lbl].attrs[\"multiscales\"][0][\"datasets\"]\n",
    "        for cds in crop_datasets:\n",
    "            if cds[\"path\"] == \"s0\":\n",
    "                crop_res = cds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "                \n",
    "                crop_off = cds[\"coordinateTransformations\"][1][\"translation\"]\n",
    "                \n",
    "                crop_off_arr = np.array(crop_off)\n",
    "                crop_res_arr = np.array(crop_res)\n",
    "                corner_off_arr = (crop_off_arr + raw_res_arr/2. - crop_res_arr/2.)\n",
    "                if np.all(crop_res_arr > np.array([8.,8.,8.])):\n",
    "                    print(f\"crop {crop} has {crop_res}\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ds_info in datas.items():\n",
    "    print(key)\n",
    "    root_raw = fst.read(ds_info[\"raw\"])\n",
    "    try:\n",
    "        datasets = root_raw.attrs[\"multiscales\"][0][\"datasets\"]\n",
    "    except KeyError as e:\n",
    "        print(\"Different metadata format?\")\n",
    "        continue\n",
    "    for ds in datasets:\n",
    "        if ds[\"path\"] == \"s0\":\n",
    "            raw_res = ds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    raw_res_arr = np.array(raw_res)\n",
    "    offsets = []\n",
    "    for crop in ds_info[\"crops\"]:\n",
    "        crop_root = fst.read(f\"{root_gt_path}{key}/groundtruth.zarr/{crop}\")\n",
    "        lbl = list(crop_root.keys())[0]\n",
    "        crop_datasets = crop_root[lbl].attrs[\"multiscales\"][0][\"datasets\"]\n",
    "        for cds in crop_datasets:\n",
    "            if cds[\"path\"] == \"s0\":\n",
    "                crop_res = cds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "                \n",
    "                crop_off = cds[\"coordinateTransformations\"][1][\"translation\"]\n",
    "                \n",
    "                print(f\"{crop}:{crop_off}\")\n",
    "                offsets.append(tuple(crop_off))\n",
    "    if len(set(offsets)) < len(offsets):\n",
    "        print(f\"This has some {len(set(offsets))}, {len(offsets)}\")\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ds_info in datas.items():\n",
    "    print(key)\n",
    "    root_raw = fst.read(ds_info[\"raw\"])\n",
    "    try:\n",
    "        datasets = root_raw.attrs[\"multiscales\"][0][\"coordinateTransformations\"]\n",
    "        if len(datasets) > 0:\n",
    "            print(f\"Check this one: {ds_info['raw']}\")\n",
    "    except KeyError as e:\n",
    "        print(\"Different metadata format?\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, ds_info in datas.items():\n",
    "    print(key)\n",
    "    root_raw = fst.read(ds_info[\"raw\"])\n",
    "    try:\n",
    "        datasets = root_raw.attrs[\"multiscales\"][0][\"datasets\"]\n",
    "    except KeyError as e:\n",
    "        print(\"Different metadata format?\")\n",
    "        continue\n",
    "    for ds in datasets:\n",
    "        if ds[\"path\"] == \"s0\":\n",
    "            raw_res = ds[\"coordinateTransformations\"][0][\"scale\"]\n",
    "    raw_res_arr = np.array(raw_res)\n",
    "        \n",
    "    for crop in ds_info[\"crops\"]:\n",
    "        crop_root = fst.read(f\"{root_gt_path}{key}/groundtruth.zarr/{crop}\")\n",
    "        if \"all\" in crop_root:\n",
    "            labels, counts = np.unique(crop_root[\"all\"][\"s0\"], return_counts=True)\n",
    "            if 0 in labels:\n",
    "                print(f\"{crop} labels: \", labels, \"INCLUDES 0\", counts)\n",
    "            else:\n",
    "                print(f\" {crop} labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 1  2  8  9 10 11 16 17 35]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
